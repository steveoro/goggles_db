1. Goggles is a framework composed of these Rails projects: goggles_db, goggles_api, goggles_main and goggles_admin2.
2. 'goggles_db' is a namespaced rails Engine storing the whole database structure for Goggles with its models, most of its Business Logic, several strategy classes and "data-oriented" decorators. This is internally referred to as the "DB" project of Goggles.
3. 'goggles_api' is a stand-alone Rails application that holds all the API endpoints with JWT-based authentication. Internally referred to as the "API" project of Goggles.
4. 'goggles_main' is a stand-alone Rails application that implements the main client UI. Internally referred to as the "Main" project of Goggles.
5. 'goggles_admin2' is a stand-alone Rails application that implements an admin web interface for managing the database and importing new data sets. Internally referred to as the "Admin2" project of Goggles.
6. 'goggles_db.wiki' is a project wiki where technical details about all the framework are documented.
7. Currently, apart from "Admin2", all other 3 projects are deployed as a single composed Docker container.
8. "Admin2" is supposed to be run only locally, accessing both a local MySql database and the remote database using either the staging or production API. Configuration for the target endpoint can at runtime.
9. "Main" has some front-end specific decorators and components. Some of these are copied over to "Admin2" for convenience with some customizations, but the base features must be kept in sync with "Admin2".
10. The "DB" project stores the shared database structure and all its models, most of its Business Logic, several strategy classes and "data-oriented" decorators.
11. The "API" project stores the API endpoints with JWT-based authentication.
12. The "Main" project has some front-end specific decorators and components. Some of these are copied over to "Admin2" for convenience with some customizations, but the base features must be kept in sync with "Admin2".
13. The "Admin2" project stores the admin web interface for managing the database and importing new data sets.
14. The "Admin2" project contains a Node JS server application with API endpoints that start a web crawler using Puppeteer, internally referred to as the "crawler" because it's the only crawler available to Admin2.
15. Both "Admin2" rails application and its Node JS "crawler" are currently run locally only. Admin2 can get the crawler status by reading updates on a local txt file at runtime.
16. The "crawler" is currently able to parse 2 different types of web pages: 1 for an event calendar (which can be in 2 different subtypes) and another one, for each event, storing the event results.
17. When crawling the event calendar, the crawler can either parse https://www.federnuoto.it/home/master/circuito-supermaster/eventi-circuito-supermaster.html or https://www.federnuoto.it/home/master/circuito-supermaster/riepilogo-eventi.html, as each event sub-page is the same for both.
18. When crawling each event, each subpage may have just a PDF link for the published results, or a series of subsections, which have to be individually clicked to render asynchronously the results, so that the crawler may store each result section into a dedicated JSON sub-array.
19. When "crawler" finds only the PDF link, the corresponding PDF needs to be converted into TXT so that it can be processed by the "Admin2" PDF parser, in order to extract the results data into our common JSON format.
20. The PDF parser of "Admin2" is able to parse PDFs using a YAML format definition file that defines the text structure and layout of every result event subtable represented on the PDF.
